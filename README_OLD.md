# Retail Analytics Pipeline

> **End-to-end retail analytics platform built with Apache Airflow 3.1.2, dbt, FastAPI, and Metabase**

A production-ready data pipeline for retail analytics, designed for Bidco Africa to analyze sales performance, detect promotions, monitor pricing strategies, and assess data quality across retail locations.

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Technology Stack](#-technology-stack)
- [Prerequisites](#-prerequisites)
- [Quick Start](#-quick-start)
- [Deployment Guide](#-deployment-guide)
- [Project Structure](#-project-structure)
- [Business Questions Answered](#-business-questions-answered)
- [API Documentation](#-api-documentation)
- [Metabase Dashboards](#-metabase-dashboards)
- [Troubleshooting](#-troubleshooting)

---

## âœ¨ Features

- **Automated ETL Pipeline**: Daily orchestration of data ingestion, transformation, and analytics
- **Data Quality Monitoring**: Automated validation and quality scoring of retail data
- **Promotion Detection**: Intelligent algorithm to identify promotional periods and measure uplift
- **Competitive Pricing Analysis**: Track Bidco's price positioning against competitors
- **REST API**: FastAPI service for programmatic access to analytics insights
- **Interactive Dashboards**: Metabase visualizations for business intelligence
- **Production-Grade Infrastructure**: Built on Apache Airflow 3.1.2 with modern best practices

---

## ğŸ—ï¸ Architecture

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Data      â”‚
â”‚  (Retail Sales) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Apache Airflow 3.1.2                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DAG: retail_analytics_pipeline      â”‚   â”‚
â”‚  â”‚                                      â”‚   â”‚
â”‚  â”‚  1. Load CSV â†’ PostgreSQL            â”‚   â”‚
â”‚  â”‚  2. Validate Data                    â”‚   â”‚
â”‚  â”‚  3. dbt Transformations              â”‚   â”‚
â”‚  â”‚  4. Generate Insights Summary        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  PostgreSQL 15  â”‚
         â”‚                 â”‚
         â”‚  Schemas:       â”‚
         â”‚  - public       â”‚
         â”‚  - retail_stagingâ”‚
         â”‚  - retail_marts â”‚
         â”‚  - retail_analyticsâ”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
              â”‚        â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI    â”‚         â”‚  Metabase    â”‚
â”‚  Port: 8001 â”‚         â”‚  Port: 3000  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Orchestration** | Apache Airflow | 3.1.2 | Workflow management |
| **Runtime** | Astronomer Runtime | 3.1-4 | Airflow distribution |
| **Transformation** | dbt Core | 1.7.18 | SQL-based transformations |
| **Database** | PostgreSQL | 15 | Data warehouse |
| **API** | FastAPI | 0.104+ | REST API service |
| **Visualization** | Metabase | 0.47.4 | Business intelligence |
| **Language** | Python | 3.12 | Backend logic |
| **Container** | Docker | Latest | Containerization |

---

## ğŸ“¦ Prerequisites

- **Docker Desktop**: Version 20.10+ with 8GB+ RAM allocated
- **Astronomer CLI**: Install via \`brew install astro\` (macOS) or from https://www.astronomer.io/docs/astro/cli/install-cli
- **System Resources**: Minimum 8GB RAM, 20GB disk space

---

## ğŸš€ Quick Start

### Step 1: Clone and Prepare Data

\`\`\`bash
git clone <repository-url>
cd retail-analytics-pipeline

# Place your CSV file
cp /path/to/retail_sales.csv include/datasets/retail_sales.csv
\`\`\`

### Step 2: Build Retail API Image

\`\`\`bash
docker build -t retail-api:latest ./include/api
\`\`\`

### Step 3: Start All Services

\`\`\`bash
astro dev start
\`\`\`

**Wait 2-3 minutes** for services to initialize.

### Step 4: Access Services

| Service | URL | Credentials |
|---------|-----|-------------|
| **Airflow UI** | http://localhost:8080 | admin / admin |
| **FastAPI Docs** | http://localhost:8001/docs | None |
| **Metabase** | http://localhost:3000 | Setup on first visit |
| **PostgreSQL** | localhost:5435 | postgres / postgres |

### Step 5: Run the Pipeline

1. Open Airflow: http://localhost:8080
2. Find DAG: \`retail_analytics_pipeline\`
3. Click **Play** button to trigger
4. Monitor in **Grid** view

**Expected runtime**: 2-5 minutes

---

## ğŸ“‚ Project Structure

\`\`\`
retail-analytics-pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ retail_analytics_pipeline.py    # Main Airflow DAG
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ Dockerfile                   # FastAPI container
â”‚   â”‚   â””â”€â”€ retail_api.py                # REST API
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â””â”€â”€ retail_sales.csv             # Input data
â”‚   â””â”€â”€ dbt/
â”‚       â”œâ”€â”€ models/retail/
â”‚       â”‚   â”œâ”€â”€ staging/                 # Data cleaning
â”‚       â”‚   â”œâ”€â”€ marts/                   # Business logic
â”‚       â”‚   â””â”€â”€ analytics/               # KPIs
â”‚       â”œâ”€â”€ macros/                      # Custom functions
â”‚       â”œâ”€â”€ dbt_project.yml
â”‚       â””â”€â”€ profiles.yml
â”œâ”€â”€ Dockerfile                           # Airflow container
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.override.yml
â””â”€â”€ README.md
\`\`\`

---

## ğŸ’¼ Business Questions Answered

### 1. Data Quality
**Metric**: Overall health score, completeness %  
**Table**: \`retail_analytics.data_quality_summary\`  
**API**: \`GET /api/data-quality\`

### 2. Promotion Effectiveness
**Metric**: Uplift %, discount depth, top performers  
**Table**: \`retail_analytics.promo_summary\`  
**API**: \`GET /api/promos\`

\`\`\`sql
SELECT product_description, promo_uplift_pct, promo_sales_value
FROM retail_marts.promo_detection
WHERE is_bidco = 1 AND is_on_promo = 1
ORDER BY promo_uplift_pct DESC LIMIT 10;
\`\`\`

### 3. Pricing Competitiveness
**Metric**: Price index, market positioning  
**Table**: \`retail_analytics.pricing_summary\`  
**API**: \`GET /api/pricing\`

### 4. Store Performance
**Metric**: Sales by store, promotion frequency  
**Table**: \`retail_marts.promo_detection\` (aggregated)

### 5. Category Insights
**Metric**: Revenue, units sold by category  
**Table**: \`retail_staging.stg_retail_sales\`

### 6. Supplier Analysis
**Metric**: Bidco vs competitor performance  
**Table**: \`retail_marts.price_comparison\`

### 7. Temporal Trends
**Metric**: Daily/weekly/monthly patterns  
**Table**: \`retail_staging.stg_retail_sales\`

### 8. SKU Performance
**Metric**: Top sellers, sales velocity  
**Table**: \`retail_marts.promo_detection\`

### 9. Data Anomalies
**Metric**: Missing values, outliers  
**Table**: \`retail_analytics.data_quality_issues\`

### 10. Baseline Performance
**Metric**: Non-promo sales levels  
**Table**: \`retail_marts.store_baselines\`

---

## ğŸ”Œ API Documentation

### Available Endpoints

\`\`\`bash
# Health check
curl http://localhost:8001/health

# Get all metrics
curl http://localhost:8001/api/metrics | jq

# Promotion data
curl http://localhost:8001/api/promos | jq

# Pricing analysis
curl http://localhost:8001/api/pricing | jq

# Data quality
curl http://localhost:8001/api/data-quality | jq
\`\`\`

**Interactive Docs**: http://localhost:8001/docs

---

## ğŸ“Š Metabase Dashboards

### Setup Instructions

1. Visit http://localhost:3000
2. Create admin account
3. Add PostgreSQL connection:
   - Host: \`postgres\` (Docker internal)
   - Port: \`5432\`
   - Database: \`postgres\`
   - User/Pass: \`postgres\` / \`postgres\`

### Recommended Dashboard: Executive Summary

**Cards**:
- Total Sales (last 30 days)
- Data Quality Score
- Active Promotions
- Bidco Market Share
- Price Position Indicator

**SQL Example**:
\`\`\`sql
SELECT
    SUM("Total_Sales") as total_sales,
    COUNT(DISTINCT "Store_Name") as stores
FROM public.retail_sales
WHERE "Date_Of_Sale" >= CURRENT_DATE - INTERVAL '30 days';
\`\`\`

---

## ğŸ”§ Troubleshooting

### CSV File Not Found
\`\`\`bash
# Verify file exists
ls -la include/datasets/retail_sales.csv

# Copy if missing
cp /path/to/data.csv include/datasets/retail_sales.csv
astro dev restart
\`\`\`

### Metabase Connection Issues
Use Docker hostname \`postgres\` (not localhost) with port \`5432\` (not 5435)

### DAG Not Appearing
\`\`\`bash
# Check for syntax errors
astro dev parse

# View logs
astro dev logs -f -s
\`\`\`

### Out of Memory
Increase Docker Desktop memory to 8GB+:
- Settings â†’ Resources â†’ Memory â†’ 8GB â†’ Apply & Restart

---

## ğŸ›‘ Stopping Services

\`\`\`bash
# Stop (preserves data)
astro dev stop

# Clean slate
astro dev kill
\`\`\`

---

## ğŸ“ˆ Production Deployment

### Step 1: Environment Variables
Create \`.env\` file:
\`\`\`env
AIRFLOW__CORE__FERNET_KEY=<generate-new-key>
AIRFLOW__WEBSERVER__SECRET_KEY=<generate-new-key>
POSTGRES_PASSWORD=<strong-password>
\`\`\`

### Step 2: Secure Configuration
- Change default Airflow credentials
- Use secrets manager for DB passwords
- Enable SSL for PostgreSQL
- Configure firewall rules

### Step 3: Deploy
\`\`\`bash
# Push to Astronomer Cloud
astro deploy

# Or use Docker Compose in production
docker-compose -f docker-compose.yml -f docker-compose.override.yml up -d
\`\`\`

---

## ğŸ“ Support

**Issues?**
1. Check [Troubleshooting](#-troubleshooting)
2. Review logs: \`astro dev logs\`
3. Contact data engineering team

---

**Built with â¤ï¸ for Bidco Africa**

*Last Updated: 2025-01-13 | Apache Airflow 3.1.2*
